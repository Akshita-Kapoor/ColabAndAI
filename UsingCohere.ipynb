{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPCjy5qBDUjt625yVK+/NNw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akshita-Kapoor/ColabAndAI/blob/main/UsingCohere.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NqTT2e-KTVf"
      },
      "outputs": [],
      "source": [
        "!pip install cohere"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cohere\n",
        "from google.colab import userdata\n",
        "k = userdata.get('COHERE_API_KEY')\n",
        "\n",
        "\n",
        "co = cohere.Client(k)\n",
        "\n",
        "response = co.generate(\n",
        "    prompt='Please briefly explain to me how Deep Learning works using at most 100 words.',\n",
        "    max_tokens=200\n",
        ")\n",
        "print(response.generations[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJ0U6Lt7KYR5",
        "outputId": "dc3866ef-188c-48e0-ab3f-1409ab7b560b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Deep learning is a type of artificial intelligence that uses multiple layers of artificial neural networks to learn and make decisions. These neural networks are designed to mimic the structure and function of the human brain, allowing the algorithm to learn from large amounts of data and improve its accuracy over time. The process involves feeding the algorithm massive amounts of data and adjusting the weights of the connections between the nodes in the networks to optimize the performance of the model. The optimized algorithm can then be deployed to make predictions or classify things ranging from images to speeches to texts. \n"
          ]
        }
      ]
    }
  ]
}